{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepSeedlings: CNN\n",
    "Using pre-trained Tensorflow CNNs (with the last layer 'cut' off) to vectorize images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [16, 10]\n",
    "plt.rcParams['font.size'] = 16\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.applications import xception\n",
    "from keras.preprocessing import image\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.regularizers import l2\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_valid_bf = np.load(os.path.join(os.getcwd(),'x_train_valid_bf.npy'))\n",
    "y_train_valid = np.load(os.path.join(os.getcwd(),'y_train_valid.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_bf = np.load(os.path.join(os.getcwd(),'x_test_bf.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Train/Validation Data\n",
    "- shuffle\n",
    "- train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use one-hot encoding for categorial labels\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]\n",
    "    index_offset = np.arange(num_labels) * num_classes\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    return labels_one_hot\n",
    "\n",
    "def one_hot_to_dense(labels_one_hot):\n",
    "    num_labels = labels_one_hot.shape[0]\n",
    "    num_classes = labels_one_hot.shape[1]\n",
    "    labels_dense = np.where(labels_one_hot == 1)[1]      \n",
    "    return labels_dense\n",
    "\n",
    "# function to shuffle randomly train and validation data\n",
    "def shuffle_train_valid_data(x_train_valid):\n",
    "    \n",
    "    print('shuffle train and validation data')\n",
    "    \n",
    "    # shuffle train and validation data of original data\n",
    "    perm_array = np.arange(len(x_train_valid)) \n",
    "    np.random.shuffle(perm_array)\n",
    "    \n",
    "    # split train and validation sets based on original data\n",
    "    x_train = x_train_valid[perm_array[:train_set_size]]\n",
    "    y_train = dense_to_one_hot(y_train_valid[perm_array[:train_set_size]], num_classes = 12)\n",
    "    x_valid = x_train_valid[perm_array[-valid_set_size:]]\n",
    "    y_valid = dense_to_one_hot(y_train_valid[perm_array[-valid_set_size:]], num_classes = 12)\n",
    "         \n",
    "    return x_train, y_train, x_valid, y_valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation sets\n",
    "valid_set_size_percentage = 10\n",
    "valid_set_size = int(len(x_train_valid_bf) * valid_set_size_percentage/100);\n",
    "train_set_size = len(x_train_valid_bf) - valid_set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle train and validation data\n"
     ]
    }
   ],
   "source": [
    "# shuffle and train/validation split\n",
    "x_train_bf, y_train, x_valid_bf, y_valid = shuffle_train_valid_data(x_train_valid_bf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_bf.shape =  (2160, 2048)\n",
      "y_train.shape =  (2160, 12)\n",
      "x_valid_bf.shape =  (240, 2048)\n",
      "y_valid.shape =  (240, 12)\n"
     ]
    }
   ],
   "source": [
    "print('x_train_bf.shape = ', x_train_bf.shape)\n",
    "print('y_train.shape = ', y_train.shape)\n",
    "print('x_valid_bf.shape = ', x_valid_bf.shape)\n",
    "print('y_valid.shape = ', y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr decay schedule\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 0.0001\n",
    "    if epoch > 20 :\n",
    "        lr *= 1e-1\n",
    "    #elif epoch > 15 :\n",
    "    #    lr *= 1e-2\n",
    "\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception CNN  with additional layers\n",
    "(best results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_size = x_train_bf.shape[1] # features \n",
    "y_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 2,363,660\n",
      "Trainable params: 2,363,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    " \n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    " \n",
    "# Add the vgg convolutional base model\n",
    "#model.add(x_conv)\n",
    " \n",
    "# Add new layers\n",
    "#model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024, input_dim = x_size, activation='relu'))\n",
    "model.add(layers.Dropout(0.33))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.33))\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    " \n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "Train on 2160 samples, validate on 240 samples\n",
      "Epoch 1/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 1s 304us/step - loss: 1.7636 - acc: 0.4569 - precision: 0.4144 - recall: 0.0449 - f1: nan - val_loss: 1.0692 - val_acc: 0.7125 - val_precision: 0.9376 - val_recall: 0.2542 - val_f1: 0.3967\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.06919, saving model to /tmp/weights.01-1.07.hdf5\n",
      "Epoch 2/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 191us/step - loss: 1.0155 - acc: 0.6880 - precision: 0.8474 - recall: 0.3958 - f1: 0.5285 - val_loss: 0.7325 - val_acc: 0.7500 - val_precision: 0.8688 - val_recall: 0.6083 - val_f1: 0.7141\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.06919 to 0.73254, saving model to /tmp/weights.02-0.73.hdf5\n",
      "Epoch 3/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.7456 - acc: 0.7551 - precision: 0.8456 - recall: 0.6097 - f1: 0.7057 - val_loss: 0.5484 - val_acc: 0.8042 - val_precision: 0.8592 - val_recall: 0.6958 - val_f1: 0.7673\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73254 to 0.54845, saving model to /tmp/weights.03-0.55.hdf5\n",
      "Epoch 4/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.6188 - acc: 0.7852 - precision: 0.8501 - recall: 0.6917 - f1: 0.7615 - val_loss: 0.4610 - val_acc: 0.8333 - val_precision: 0.8809 - val_recall: 0.7750 - val_f1: 0.8234\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.54845 to 0.46101, saving model to /tmp/weights.04-0.46.hdf5\n",
      "Epoch 5/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 191us/step - loss: 0.5268 - acc: 0.8319 - precision: 0.8822 - recall: 0.7644 - f1: 0.8181 - val_loss: 0.3964 - val_acc: 0.8500 - val_precision: 0.8843 - val_recall: 0.8167 - val_f1: 0.8486\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.46101 to 0.39639, saving model to /tmp/weights.05-0.40.hdf5\n",
      "Epoch 6/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.4500 - acc: 0.8560 - precision: 0.9010 - recall: 0.7972 - f1: 0.8449 - val_loss: 0.3630 - val_acc: 0.8583 - val_precision: 0.8753 - val_recall: 0.8167 - val_f1: 0.8447\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.39639 to 0.36297, saving model to /tmp/weights.06-0.36.hdf5\n",
      "Epoch 7/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.4055 - acc: 0.8648 - precision: 0.9013 - recall: 0.8185 - f1: 0.8570 - val_loss: 0.3695 - val_acc: 0.8417 - val_precision: 0.8689 - val_recall: 0.8167 - val_f1: 0.8417\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 188us/step - loss: 0.3694 - acc: 0.8787 - precision: 0.9053 - recall: 0.8440 - f1: 0.8730 - val_loss: 0.3237 - val_acc: 0.8667 - val_precision: 0.8749 - val_recall: 0.8417 - val_f1: 0.8578\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.36297 to 0.32367, saving model to /tmp/weights.08-0.32.hdf5\n",
      "Epoch 9/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 191us/step - loss: 0.3253 - acc: 0.8995 - precision: 0.9230 - recall: 0.8713 - f1: 0.8960 - val_loss: 0.3204 - val_acc: 0.8667 - val_precision: 0.9078 - val_recall: 0.8583 - val_f1: 0.8822\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.32367 to 0.32035, saving model to /tmp/weights.09-0.32.hdf5\n",
      "Epoch 10/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 196us/step - loss: 0.3148 - acc: 0.8935 - precision: 0.9172 - recall: 0.8644 - f1: 0.8896 - val_loss: 0.3215 - val_acc: 0.8750 - val_precision: 0.8970 - val_recall: 0.8667 - val_f1: 0.8813\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 192us/step - loss: 0.2776 - acc: 0.9125 - precision: 0.9312 - recall: 0.8866 - f1: 0.9079 - val_loss: 0.2969 - val_acc: 0.8792 - val_precision: 0.9001 - val_recall: 0.8625 - val_f1: 0.8807\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.32035 to 0.29687, saving model to /tmp/weights.11-0.30.hdf5\n",
      "Epoch 12/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 191us/step - loss: 0.2457 - acc: 0.9315 - precision: 0.9486 - recall: 0.9097 - f1: 0.9285 - val_loss: 0.3120 - val_acc: 0.8792 - val_precision: 0.8968 - val_recall: 0.8625 - val_f1: 0.8790\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 191us/step - loss: 0.2353 - acc: 0.9264 - precision: 0.9389 - recall: 0.9056 - f1: 0.9217 - val_loss: 0.3156 - val_acc: 0.8750 - val_precision: 0.8931 - val_recall: 0.8583 - val_f1: 0.8751\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 191us/step - loss: 0.2169 - acc: 0.9292 - precision: 0.9432 - recall: 0.9144 - f1: 0.9284 - val_loss: 0.3076 - val_acc: 0.8833 - val_precision: 0.8976 - val_recall: 0.8667 - val_f1: 0.8815\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.1971 - acc: 0.9421 - precision: 0.9563 - recall: 0.9269 - f1: 0.9411 - val_loss: 0.2846 - val_acc: 0.8833 - val_precision: 0.8936 - val_recall: 0.8667 - val_f1: 0.8796\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.29687 to 0.28459, saving model to /tmp/weights.15-0.28.hdf5\n",
      "Epoch 16/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 188us/step - loss: 0.1902 - acc: 0.9403 - precision: 0.9498 - recall: 0.9208 - f1: 0.9348 - val_loss: 0.2864 - val_acc: 0.8917 - val_precision: 0.9027 - val_recall: 0.8833 - val_f1: 0.8928\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.1671 - acc: 0.9495 - precision: 0.9569 - recall: 0.9384 - f1: 0.9474 - val_loss: 0.2975 - val_acc: 0.8792 - val_precision: 0.8962 - val_recall: 0.8542 - val_f1: 0.8743\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 189us/step - loss: 0.1557 - acc: 0.9537 - precision: 0.9626 - recall: 0.9417 - f1: 0.9519 - val_loss: 0.2886 - val_acc: 0.8917 - val_precision: 0.9021 - val_recall: 0.8792 - val_f1: 0.8904\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 191us/step - loss: 0.1494 - acc: 0.9532 - precision: 0.9599 - recall: 0.9435 - f1: 0.9515 - val_loss: 0.2891 - val_acc: 0.8875 - val_precision: 0.8934 - val_recall: 0.8708 - val_f1: 0.8819\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 191us/step - loss: 0.1377 - acc: 0.9569 - precision: 0.9668 - recall: 0.9468 - f1: 0.9565 - val_loss: 0.2860 - val_acc: 0.8833 - val_precision: 0.9056 - val_recall: 0.8792 - val_f1: 0.8920\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 0s 189us/step - loss: 0.1204 - acc: 0.9602 - precision: 0.9666 - recall: 0.9528 - f1: 0.9595 - val_loss: 0.2965 - val_acc: 0.8750 - val_precision: 0.8892 - val_recall: 0.8708 - val_f1: 0.8799\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 188us/step - loss: 0.1124 - acc: 0.9639 - precision: 0.9727 - recall: 0.9556 - f1: 0.9639 - val_loss: 0.2655 - val_acc: 0.9083 - val_precision: 0.9242 - val_recall: 0.9083 - val_f1: 0.9161\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.28459 to 0.26546, saving model to /tmp/weights.22-0.27.hdf5\n",
      "Epoch 23/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 192us/step - loss: 0.1003 - acc: 0.9727 - precision: 0.9762 - recall: 0.9671 - f1: 0.9716 - val_loss: 0.2707 - val_acc: 0.9125 - val_precision: 0.9196 - val_recall: 0.9000 - val_f1: 0.9096\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 192us/step - loss: 0.0999 - acc: 0.9745 - precision: 0.9758 - recall: 0.9681 - f1: 0.9718 - val_loss: 0.2720 - val_acc: 0.9167 - val_precision: 0.9235 - val_recall: 0.9042 - val_f1: 0.9137\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/40\n",
      "Learning rate:  1e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160/2160 [==============================] - 0s 193us/step - loss: 0.0932 - acc: 0.9764 - precision: 0.9796 - recall: 0.9745 - f1: 0.9770 - val_loss: 0.2773 - val_acc: 0.9083 - val_precision: 0.9197 - val_recall: 0.9000 - val_f1: 0.9096\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.0940 - acc: 0.9755 - precision: 0.9817 - recall: 0.9694 - f1: 0.9754 - val_loss: 0.2762 - val_acc: 0.9125 - val_precision: 0.9238 - val_recall: 0.9042 - val_f1: 0.9138\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 191us/step - loss: 0.0936 - acc: 0.9759 - precision: 0.9785 - recall: 0.9718 - f1: 0.9751 - val_loss: 0.2778 - val_acc: 0.9083 - val_precision: 0.9161 - val_recall: 0.9042 - val_f1: 0.9101\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 196us/step - loss: 0.0935 - acc: 0.9727 - precision: 0.9784 - recall: 0.9690 - f1: 0.9736 - val_loss: 0.2767 - val_acc: 0.9125 - val_precision: 0.9239 - val_recall: 0.9042 - val_f1: 0.9138\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 192us/step - loss: 0.0905 - acc: 0.9745 - precision: 0.9780 - recall: 0.9676 - f1: 0.9727 - val_loss: 0.2782 - val_acc: 0.9167 - val_precision: 0.9240 - val_recall: 0.9042 - val_f1: 0.9138\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 192us/step - loss: 0.0894 - acc: 0.9736 - precision: 0.9804 - recall: 0.9704 - f1: 0.9753 - val_loss: 0.2778 - val_acc: 0.9083 - val_precision: 0.9114 - val_recall: 0.8958 - val_f1: 0.9034\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.0850 - acc: 0.9764 - precision: 0.9785 - recall: 0.9727 - f1: 0.9756 - val_loss: 0.2775 - val_acc: 0.9083 - val_precision: 0.9197 - val_recall: 0.9000 - val_f1: 0.9096\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.0848 - acc: 0.9787 - precision: 0.9823 - recall: 0.9750 - f1: 0.9786 - val_loss: 0.2770 - val_acc: 0.9125 - val_precision: 0.9240 - val_recall: 0.9042 - val_f1: 0.9138\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 193us/step - loss: 0.0772 - acc: 0.9838 - precision: 0.9860 - recall: 0.9796 - f1: 0.9827 - val_loss: 0.2815 - val_acc: 0.9083 - val_precision: 0.9192 - val_recall: 0.8958 - val_f1: 0.9072\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 192us/step - loss: 0.0758 - acc: 0.9833 - precision: 0.9873 - recall: 0.9796 - f1: 0.9834 - val_loss: 0.2828 - val_acc: 0.9083 - val_precision: 0.9158 - val_recall: 0.9000 - val_f1: 0.9077\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 189us/step - loss: 0.0786 - acc: 0.9806 - precision: 0.9841 - recall: 0.9764 - f1: 0.9801 - val_loss: 0.2840 - val_acc: 0.9083 - val_precision: 0.9200 - val_recall: 0.9042 - val_f1: 0.9119\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.0798 - acc: 0.9819 - precision: 0.9846 - recall: 0.9764 - f1: 0.9804 - val_loss: 0.2792 - val_acc: 0.9083 - val_precision: 0.9200 - val_recall: 0.9042 - val_f1: 0.9119\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 192us/step - loss: 0.0765 - acc: 0.9801 - precision: 0.9823 - recall: 0.9764 - f1: 0.9793 - val_loss: 0.2778 - val_acc: 0.9125 - val_precision: 0.9240 - val_recall: 0.9042 - val_f1: 0.9138\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 190us/step - loss: 0.0768 - acc: 0.9819 - precision: 0.9851 - recall: 0.9792 - f1: 0.9821 - val_loss: 0.2776 - val_acc: 0.9125 - val_precision: 0.9160 - val_recall: 0.9042 - val_f1: 0.9099\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 191us/step - loss: 0.0795 - acc: 0.9796 - precision: 0.9823 - recall: 0.9731 - f1: 0.9776 - val_loss: 0.2738 - val_acc: 0.9083 - val_precision: 0.9197 - val_recall: 0.9000 - val_f1: 0.9096\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/40\n",
      "Learning rate:  1e-05\n",
      "2160/2160 [==============================] - 0s 189us/step - loss: 0.0750 - acc: 0.9829 - precision: 0.9847 - recall: 0.9769 - f1: 0.9807 - val_loss: 0.2744 - val_acc: 0.9167 - val_precision: 0.9242 - val_recall: 0.9083 - val_f1: 0.9161\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "tensorboard = TensorBoard(log_dir = './logs')\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/weights.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=lr_schedule(0)),\n",
    "              metrics=['acc', precision, recall, f1])\n",
    "\n",
    "lr = LearningRateScheduler(lr_schedule)\n",
    "# Train the model\n",
    "\n",
    " \n",
    "history = model.fit(x=x_train_bf, y=y_train,  epochs=40, verbose=1, validation_data=(x_valid_bf, y_valid), callbacks = [tensorboard, checkpointer, lr])\n",
    "                    #callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, \n",
    "                    #class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None)\n",
    "# Save the model\n",
    "#model.save('small_last4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('xception_seedlings.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240/240 [==============================] - 0s 124us/step\n"
     ]
    }
   ],
   "source": [
    "y_valid_predict_proba = model.predict(x_valid_bf, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_predict_species = []\n",
    "for pred in y_valid_predict_proba:\n",
    "    y_valid_predict_species.append(np.argmax(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(one_hot_to_dense(y_valid), y_valid_predict_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  0,  0,  0,  1,  0,  6,  0,  0,  0,  0,  0],\n",
       "       [ 0, 19,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1, 21,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 20,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 17,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 22,  0,  0,  0,  0,  0,  0],\n",
       "       [ 5,  0,  0,  0,  0,  0, 12,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0, 26,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 13,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0,  2, 25,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 14,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0, 17]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.67      0.70        21\n",
      "          1       0.90      1.00      0.95        19\n",
      "          2       0.95      0.95      0.95        22\n",
      "          3       1.00      0.95      0.98        21\n",
      "          4       0.94      1.00      0.97        17\n",
      "          5       0.96      1.00      0.98        22\n",
      "          6       0.67      0.71      0.69        17\n",
      "          7       0.93      0.96      0.95        27\n",
      "          8       0.87      1.00      0.93        13\n",
      "          9       1.00      0.89      0.94        28\n",
      "         10       1.00      1.00      1.00        14\n",
      "         11       1.00      0.89      0.94        19\n",
      "\n",
      "avg / total       0.92      0.92      0.92       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(one_hot_to_dense(y_valid), y_valid_predict_species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f88dc511780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abbreviation = ['BG', 'Ch', 'Cl', 'CC', 'CW', 'FH', 'LSB', 'M', 'SM', 'SP', 'SFC', 'SB']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax = sns.heatmap(cnf_matrix, ax=ax, cmap=plt.cm.Greens, annot=True)\n",
    "ax.set_xticklabels(abbreviation)\n",
    "ax.set_yticklabels(abbreviation)\n",
    "plt.title('Confusion matrix of validation set')\n",
    "plt.ylabel('True species')\n",
    "plt.xlabel('Predicted species')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try retraining part of XCeption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_valid = np.load(os.path.join(os.getcwd(),'x_train_valid_imgs.npy'))\n",
    "y_train_valid = np.load(os.path.join(os.getcwd(),'y_train_valid.npy'))\n",
    "x_test = np.load(os.path.join(os.getcwd(),'x_test_imgs.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and validation sets\n",
    "valid_set_size_percentage = 10\n",
    "valid_set_size = int(len(x_train_valid) * valid_set_size_percentage/100);\n",
    "train_set_size = len(x_train_valid) - valid_set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle train and validation data\n"
     ]
    }
   ],
   "source": [
    "# shuffle and train/validation split\n",
    "x_train, y_train, x_valid, y_valid = shuffle_train_valid_data(x_train_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_conv = xception.Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3), pooling = 'avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Freeze the layers except the last 4 layers\n",
    "for layer in x_conv.layers[:-4]:\n",
    "    layer.trainable = False\n",
    " \n",
    "## Check the trainable status of the individual layers\n",
    "#for layer in x_conv.layers:\n",
    "#    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 23,225,140\n",
      "Trainable params: 5,527,308\n",
      "Non-trainable params: 17,697,832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    " \n",
    "# Create the model\n",
    "model = models.Sequential()\n",
    " \n",
    "# Add the vgg convolutional base model\n",
    "model.add(x_conv)\n",
    " \n",
    "# Add new layers\n",
    "#model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1024,  activation='relu'))\n",
    "model.add(layers.Dropout(0.33))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.33))\n",
    "model.add(layers.Dense(12, activation='softmax'))\n",
    " \n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "Train on 2160 samples, validate on 240 samples\n",
      "Epoch 1/40\n",
      "Learning rate:  0.0001\n",
      "2160/2160 [==============================] - 50s 23ms/step - loss: 1.7833 - acc: 0.4736 - precision: 0.4815 - recall: 0.0713 - f1: nan - val_loss: 1.7510 - val_acc: 0.3958 - val_precision: 0.3758 - val_recall: 0.1333 - val_f1: nan\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.75095, saving model to /tmp/weights.01-1.75.hdf5\n",
      "Epoch 2/40\n",
      "Learning rate:  0.0001\n",
      "  64/2160 [..............................] - ETA: 41s - loss: 1.1606 - acc: 0.7656 - precision: 0.9583 - recall: 0.2812 - f1: 0.4295"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-33468d255801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                     \u001b[0;31m#callbacks=None, validation_split=0.0, validation_data=None, shuffle=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0;31m#class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1710\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "tensorboard = TensorBoard(log_dir = './logs')\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/weights.{epoch:02d}-{val_loss:.2f}.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=lr_schedule(0)),\n",
    "              metrics=['acc', precision, recall, f1])\n",
    "\n",
    "lr = LearningRateScheduler(lr_schedule)\n",
    "# Train the model\n",
    "\n",
    " \n",
    "history = model.fit(x=x_train, y=y_train,  epochs=40, verbose=1, validation_data=(x_valid, y_valid), callbacks = [tensorboard, checkpointer, lr])\n",
    "                    #callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, \n",
    "                    #class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None)\n",
    "# Save the model\n",
    "#model.save('small_last4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
